# Pipeline Data Vultr

## **1ï¸âƒ£ Architecture du Pipeline**
Le pipeline de donnÃ©es suit lâ€™architecture suivante :

```
CSV (Source) â†’ MySQL (Stockage temporaire) â†’ DBT (Transformation) â†’ Vertica (Stockage Analytique) â†’ Metabase (Visualisation)
```

```
GitHub (Code & CI/CD) â†’ Vultr (Ubuntu) â†’ Docker Compose (Services) â†’ Airflow (Orchestration)
```


### **ğŸ”¹ Description des composants**
- **GitHub** : Contient le code source et gÃ¨re lâ€™intÃ©gration et le dÃ©ploiement continu (CI/CD) avec GitHub Actions.
- **Vultr (Ubuntu)** : HÃ©berge les services Docker pour exÃ©cuter lâ€™ensemble du pipeline.
- **Docker Compose** : GÃ¨re le dÃ©ploiement des services (MySQL, DBT, Vertica, Metabase, Airflow).
- **Airflow** : Orchestration des tÃ¢ches ETL (extraction, transformation, chargement des donnÃ©es).
- **CSV** : Fichier source contenant les donnÃ©es brutes.
- **MySQL** : Stockage temporaire des donnÃ©es avant transformation.
- **DBT (Data Build Tool)** : Transformation et modÃ©lisation des donnÃ©es.
- **Vertica** : Stockage analytique des donnÃ©es transformÃ©es.
- **Metabase** : Visualisation des donnÃ©es stockÃ©es dans Vertica.

---

## **2ï¸âƒ£ Stack Technologique**
| Technologie | RÃ´le |
|------------|------|
| **GitHub Actions** | CI/CD pour dÃ©ploiement automatique |
| **Docker & Docker Compose** | Conteneurisation et orchestration des services |
| **CSV** | Source des donnÃ©es brutes |
| **MySQL** | Stockage intermÃ©diaire des donnÃ©es |
| **DBT** | Transformation et modÃ©lisation des donnÃ©es |
| **Vertica** | Stockage analytique (Data Warehouse) |
| **Metabase** | Visualisation et exploration des donnÃ©es |
| **Apache Airflow** | Orchestration des tÃ¢ches ETL |

---

## **3ï¸âƒ£ Arborescence du Projet**

```
pipeline-data-vultr/
â”‚â”€â”€ dags/                         # DAGs pour Airflow (orchestration)
â”‚   â”œâ”€â”€ csv_to_mysql.py           # DAG orchestrant l'ingestion CSV â†’ MySQL
â”‚   â”œâ”€â”€ mysql_to_vertica.py       # DAG orchestrant l'ETL MySQL â†’ Vertica
â”‚â”€â”€ dbt_project/                   # Projet DBT (modÃ©lisation SQL)
â”‚   â”œâ”€â”€ profiles.yml               # Configuration DBT pour Vertica
â”‚   â”œâ”€â”€ models/                    # ModÃ¨les SQL pour la transformation
â”‚â”€â”€ scripts/                       # Scripts Python pour ingestion
â”‚   â”œâ”€â”€ create_mysql_table.py      # Script de crÃ©ation de table dans MySQL
â”‚   â”œâ”€â”€ load_csv_to_mysql.py       # Script de chargement CSV â†’ MySQL
â”‚   â”œâ”€â”€ transfer_data.py           # Script de transfert MySQL â†’ Vertica
â”‚â”€â”€ data/                          # Dossier contenant les fichiers CSV
â”‚   â”œâ”€â”€ inverter.csv               # Fichier CSV contenant les donnÃ©es des onduleurs
â”‚â”€â”€ .github/workflows/             # CI/CD GitHub Actions (dÃ©ploiement auto)
â”‚   â”œâ”€â”€ deploy.yml                 # Pipeline CI/CD pour Vultr
â”‚â”€â”€ docker-compose.yml             # DÃ©ploiement multi-services avec Docker
â”‚â”€â”€ README.md                      # Documentation du projet
```

---

## **4ï¸âƒ£ Description des Composants du Projet**

### **ğŸ“Œ 1. `docker-compose.yml`**
DÃ©finit et orchestre les services du pipeline :
- **CSV** : Source des donnÃ©es.
- **MySQL** : Stocke temporairement les donnÃ©es brutes.
- **Vertica** : Stocke les donnÃ©es transformÃ©es.
- **DBT** : Transforme les donnÃ©es avant stockage.
- **Metabase** : Visualisation des donnÃ©es.
- **Airflow** : Orchestration ETL.
- **Transfer** : Extrait, transforme et charge les donnÃ©es.

### **ğŸ“Œ 2. `scripts/load_csv_to_mysql.py`**
- **Charge** les donnÃ©es depuis le fichier `inverter.csv` vers MySQL.

### **ğŸ“Œ 3. `scripts/transfer_data.py`**
- **Extrait** les donnÃ©es de MySQL.
- **Transforme** les donnÃ©es avec DBT.
- **Charge** les donnÃ©es transformÃ©es dans Vertica.

### **ğŸ“Œ 4. `dags/csv_to_mysql.py`**
- Automatisation avec **Apache Airflow**.
- Charge les fichiers CSV vers MySQL automatiquement.

### **ğŸ“Œ 5. `dags/mysql_to_vertica.py`**
- Orchestration de la transformation et du chargement des donnÃ©es avec DBT et Vertica.

### **ğŸ“Œ 6. `.github/workflows/deploy.yml`**
- DÃ©ploiement **automatique** du pipeline sur **Vultr** aprÃ¨s chaque `git push`.
- Connexion SSH sÃ©curisÃ©e avec un **secret GitHub** (`VULTR_SSH_KEY`).

---

## **5ï¸âƒ£ DÃ©ploiement du Projet**
### **ğŸ”¹ 1. Cloner le Projet sur Vultr**
```bash
git clone https://github.com/ton_username/pipeline-data-vultr.git
cd pipeline-data-vultr
```

### **ğŸ”¹ 2. Lancer Docker Compose**
```bash
docker-compose up -d
```

### **ğŸ”¹ 3. VÃ©rifier les Conteneurs**
```bash
docker ps
```

### **ğŸ”¹ 4. AccÃ©der aux Services**
| Service | URL / Commande |
|------------|--------------------|
| **Metabase** | `http://your_server_ip:3000` |
| **Airflow** | `http://your_server_ip:8080` |
| **MySQL** | `mysql -u user -p -h your_server_ip -D mydb` |
| **Vertica** | `/opt/vertica/bin/vsql -U dbadmin -d mywarehouse` |

---

## **6ï¸âƒ£ Automatisation avec GitHub Actions**
Chaque **push sur `main`** dÃ©clenche **GitHub Actions** qui :
1. **Se connecte Ã  Vultr via SSH**.
2. **Met Ã  jour le code** avec `git pull`.
3. **RedÃ©marre Docker Compose** pour appliquer les modifications.



